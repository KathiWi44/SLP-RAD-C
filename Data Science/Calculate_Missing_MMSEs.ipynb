{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ab802-9682-41cf-b708-14afee3360c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6924e-1f4f-4de3-8de1-db2a9022c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../PROCESS-V1/dem-info.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2c88b-96c7-46f4-9117-bff949ae6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix 66* string value in Age column\n",
    "# df['Age'].value_counts()\n",
    "# Funktion zum Einlesen und Vorprozessieren der Daten\n",
    "\n",
    "def load_process(path):\n",
    "    df = pd.read_csv(f'{path}/dem-info.csv')\n",
    "    df['Age'] = df['Age'].apply(lambda x: x.replace('66*', '66'))\n",
    "    df['Age'] = df['Age'].astype(int)\n",
    "\n",
    "    for ext in [\"CTD\", \"PFT\", 'SFT']:\n",
    "        df[f'{ext}_wav'] = f'{path}/' + df['Record-ID'] + '/' + df['Record-ID'] + f'__{ext}.wav'\n",
    "        df[f'{ext}_txt'] = f'{path}/' + df['Record-ID'] + '/' + df['Record-ID'] + f'__{ext}.txt'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144417a7-5d76-4d77-bac2-1e573967ccc3",
   "metadata": {},
   "source": [
    "## Calculate Word_Count_CTD and Total_Wait_Time_CTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13790525-8dc0-4141-938a-4d17381afd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count_and_wait_time(text_path):\n",
    "    \"\"\"\n",
    "    Analysiert eine Textdatei, extrahiert die Anzahl der Wörter und die gesamte Wartezeit.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(text_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Wartezeiten extrahieren und summieren\n",
    "        wait_times = re.findall(r'\\((\\d+) seconds?\\)', content)\n",
    "        total_wait_time = sum(int(seconds) for seconds in wait_times)\n",
    "\n",
    "       # Wörter zählen\n",
    "        words = re.sub(r'\\(\\d+ seconds?\\)', '', content)  # Entferne die Wartezeiten aus dem Text\n",
    "        word_count = len(words.split())\n",
    "\n",
    "        return word_count, total_wait_time\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Fehler beim Verarbeiten von {text_path}: {e}')\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78451ff6-d738-43d3-889e-c855ffad3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recordings(folder_path, dem_info_path):\n",
    "    \"\"\"\n",
    "    Iteriert durch alle Textdateien im Ordner, berechnet die Wortanzahl und Wartezeit,\n",
    "    und fügt zusätzliche Informationen aus der dem-info.csv hinzu.\n",
    "    \"\"\"\n",
    "    # Lade die dem-info.csv-Datei\n",
    "    dem_info = pd.read_csv(dem_info_path)\n",
    "    \n",
    "    # Fixiere fehlerhafte Werte in der Age-Spalte\n",
    "    dem_info['Age'] = dem_info['Age'].apply(lambda x: x.replace('66*', '66') if isinstance(x, str) else x)\n",
    "    dem_info['Age'] = dem_info['Age'].astype(int)\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith((\".txt\")):\n",
    "                # Art des Textes bestimmen (CTD, PFT, SFT)\n",
    "                if \"__CTD\" in file:\n",
    "                    text_type = \"CTD\"\n",
    "                else:\n",
    "                    continue  # Überspringe Dateien ohne passenden Texttyp\n",
    "\n",
    "                text_path = os.path.join(root, file)\n",
    "\n",
    "                # Record-ID extrahieren\n",
    "                record_id = os.path.basename(root)\n",
    "\n",
    "                # Wortanzahl und Wartezeit berechnen\n",
    "                word_count, total_wait_time = get_word_count_and_wait_time(text_path)\n",
    "\n",
    "                # Zusätzliche Informationen aus dem DataFrame holen\n",
    "                dem_info_row = dem_info[dem_info['Record-ID'] == record_id]\n",
    "                if not dem_info_row.empty:\n",
    "                    train_or_dev = dem_info_row.iloc[0]['TrainOrDev']\n",
    "                    rec_class = dem_info_row.iloc[0]['Class']\n",
    "                    gender = dem_info_row.iloc[0]['Gender']\n",
    "                    age = dem_info_row.iloc[0]['Age']\n",
    "                    converted_mmse = dem_info_row.iloc[0]['Converted-MMSE']\n",
    "                else:\n",
    "                    train_or_dev = None\n",
    "                    rec_class = None\n",
    "                    gender = None\n",
    "                    age = None\n",
    "                    converted_mmse = None\n",
    "\n",
    "                records.append({\n",
    "                    \"Record-ID\": record_id,\n",
    "                    \"TrainOrDev\": train_or_dev,\n",
    "                    \"Class\": rec_class,\n",
    "                    \"Gender\": gender,\n",
    "                    \"Age\": age,\n",
    "                    \"Word_Count_CTD\": word_count,\n",
    "                    \"Total_Wait_Time_CTD\": total_wait_time,\n",
    "                    \"Converted-MMSE\": converted_mmse\n",
    "                })\n",
    "\n",
    "    # Konvertiere die Ergebnisse in einen DataFrame\n",
    "    results_df = pd.DataFrame(records)\n",
    "\n",
    "    # Gruppieren nach Record-ID und zusammenfassen\n",
    "    results_df = results_df.groupby(\"Record-ID\").first().reset_index()\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5410c6a5-7845-4fbc-8bad-767b62f95ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Zwischenstand.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d778549-6186-44e9-add3-7fbc2f2a220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../PROCESS-V1\"\n",
    "dem_info_path = \"../PROCESS-V1/dem-info.csv\"\n",
    "\n",
    "results_df = process_recordings(folder_path, dem_info_path)\n",
    "results_df = results_df.drop(index = 0).reset_index(drop = True)\n",
    "\n",
    "# Reihenfolge der Spalten festlegen\n",
    "final_columns = [ \"Record-ID\", \"TrainOrDev\", \"Class\", \"Gender\", \"Age\", \"Word_Count_CTD\", \"Total_Wait_Time_CTD\", \"Converted-MMSE\" ]\n",
    "\n",
    "results_df = results_df[final_columns]\n",
    "results_df.to_csv(\"Zwischenstand.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ae713-9c17-4721-b545-5ef633bb1cca",
   "metadata": {},
   "source": [
    "## Calculate TF and IDF on behalf of word count and total wait time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dca4ce9b-d8ac-41ea-a8be-5b58004ec9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and clean text files\n",
    "def read_and_clean_text(text_path):\n",
    "    with open(text_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Remove numbers and filler words\n",
    "    content = re.sub(r'\\b\\d+\\b', '', content) # Remove numbers\n",
    "    filler_words = [\"second\", \"seconds\", \"um\"]\n",
    "    content = ' '.join([word for word in content.split() if word.lower() not in filler_words])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a68c52ca-b308-48e5-b764-14131496e9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record-ID</th>\n",
       "      <th>TrainOrDev</th>\n",
       "      <th>Class</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Word_Count_CTD</th>\n",
       "      <th>Total_Wait_Time_CTD</th>\n",
       "      <th>Converted-MMSE</th>\n",
       "      <th>and_x</th>\n",
       "      <th>er_x</th>\n",
       "      <th>...</th>\n",
       "      <th>and_y</th>\n",
       "      <th>er_y</th>\n",
       "      <th>in_y</th>\n",
       "      <th>is_y</th>\n",
       "      <th>it_y</th>\n",
       "      <th>of_y</th>\n",
       "      <th>on_y</th>\n",
       "      <th>second_y</th>\n",
       "      <th>the_y</th>\n",
       "      <th>to_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Process-rec-001</td>\n",
       "      <td>train</td>\n",
       "      <td>MCI</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>210</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.264722</td>\n",
       "      <td>0.220946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264722</td>\n",
       "      <td>0.220946</td>\n",
       "      <td>0.051420</td>\n",
       "      <td>0.278501</td>\n",
       "      <td>0.174735</td>\n",
       "      <td>0.205679</td>\n",
       "      <td>0.183324</td>\n",
       "      <td>0.053809</td>\n",
       "      <td>0.812166</td>\n",
       "      <td>0.178732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Process-rec-002</td>\n",
       "      <td>dev</td>\n",
       "      <td>MCI</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.454769</td>\n",
       "      <td>0.284675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454769</td>\n",
       "      <td>0.284675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354301</td>\n",
       "      <td>0.415974</td>\n",
       "      <td>0.550749</td>\n",
       "      <td>0.230284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Process-rec-003</td>\n",
       "      <td>train</td>\n",
       "      <td>MCI</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.326950</td>\n",
       "      <td>0.081865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326950</td>\n",
       "      <td>0.081865</td>\n",
       "      <td>0.076209</td>\n",
       "      <td>0.343969</td>\n",
       "      <td>0.086324</td>\n",
       "      <td>0.152417</td>\n",
       "      <td>0.339627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633526</td>\n",
       "      <td>0.463567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Process-rec-004</td>\n",
       "      <td>dev</td>\n",
       "      <td>MCI</td>\n",
       "      <td>female</td>\n",
       "      <td>67.0</td>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.395836</td>\n",
       "      <td>0.141591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395836</td>\n",
       "      <td>0.141591</td>\n",
       "      <td>0.131807</td>\n",
       "      <td>0.475932</td>\n",
       "      <td>0.074651</td>\n",
       "      <td>0.197711</td>\n",
       "      <td>0.176222</td>\n",
       "      <td>0.206896</td>\n",
       "      <td>0.547861</td>\n",
       "      <td>0.400884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Process-rec-005</td>\n",
       "      <td>train</td>\n",
       "      <td>MCI</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.278998</td>\n",
       "      <td>0.523938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278998</td>\n",
       "      <td>0.523938</td>\n",
       "      <td>0.162578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184158</td>\n",
       "      <td>0.650314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405457</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Process-rec-153</td>\n",
       "      <td>train</td>\n",
       "      <td>HC</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.087269</td>\n",
       "      <td>0.218513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087269</td>\n",
       "      <td>0.218513</td>\n",
       "      <td>0.101707</td>\n",
       "      <td>0.275434</td>\n",
       "      <td>0.230414</td>\n",
       "      <td>0.305121</td>\n",
       "      <td>0.090652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760947</td>\n",
       "      <td>0.353527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Process-rec-154</td>\n",
       "      <td>train</td>\n",
       "      <td>HC</td>\n",
       "      <td>female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>222</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.302879</td>\n",
       "      <td>0.189595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302879</td>\n",
       "      <td>0.189595</td>\n",
       "      <td>0.176495</td>\n",
       "      <td>0.424860</td>\n",
       "      <td>0.266562</td>\n",
       "      <td>0.176495</td>\n",
       "      <td>0.104874</td>\n",
       "      <td>0.123129</td>\n",
       "      <td>0.635791</td>\n",
       "      <td>0.357865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Process-rec-155</td>\n",
       "      <td>train</td>\n",
       "      <td>HC</td>\n",
       "      <td>male</td>\n",
       "      <td>86.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129056</td>\n",
       "      <td>0.240276</td>\n",
       "      <td>0.433797</td>\n",
       "      <td>0.272169</td>\n",
       "      <td>0.360414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599229</td>\n",
       "      <td>0.417592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Process-rec-156</td>\n",
       "      <td>train</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.438701</td>\n",
       "      <td>0.366155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438701</td>\n",
       "      <td>0.366155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170427</td>\n",
       "      <td>0.151904</td>\n",
       "      <td>0.178345</td>\n",
       "      <td>0.708386</td>\n",
       "      <td>0.296197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Process-rec-157</td>\n",
       "      <td>train</td>\n",
       "      <td>HC</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>261</td>\n",
       "      <td>14</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.141409</td>\n",
       "      <td>0.672741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141409</td>\n",
       "      <td>0.672741</td>\n",
       "      <td>0.164804</td>\n",
       "      <td>0.148769</td>\n",
       "      <td>0.149343</td>\n",
       "      <td>0.263687</td>\n",
       "      <td>0.117513</td>\n",
       "      <td>0.034492</td>\n",
       "      <td>0.575411</td>\n",
       "      <td>0.200497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Record-ID TrainOrDev     Class  Gender   Age  Word_Count_CTD  \\\n",
       "0    Process-rec-001      train       MCI    male  62.0             210   \n",
       "1    Process-rec-002        dev       MCI    male  61.0              69   \n",
       "2    Process-rec-003      train       MCI  female  62.0             143   \n",
       "3    Process-rec-004        dev       MCI  female  67.0             161   \n",
       "4    Process-rec-005      train       MCI    male  65.0              45   \n",
       "..               ...        ...       ...     ...   ...             ...   \n",
       "152  Process-rec-153      train        HC    male  63.0             112   \n",
       "153  Process-rec-154      train        HC  female  79.0             222   \n",
       "154  Process-rec-155      train        HC    male  86.0              91   \n",
       "155  Process-rec-156      train  Dementia    male  61.0              48   \n",
       "156  Process-rec-157      train        HC    male  65.0             261   \n",
       "\n",
       "     Total_Wait_Time_CTD  Converted-MMSE     and_x      er_x  ...     and_y  \\\n",
       "0                      3            25.0  0.264722  0.220946  ...  0.264722   \n",
       "1                     14            25.0  0.454769  0.284675  ...  0.454769   \n",
       "2                      3            29.0  0.326950  0.081865  ...  0.326950   \n",
       "3                      2            29.0  0.395836  0.141591  ...  0.395836   \n",
       "4                      0            27.0  0.278998  0.523938  ...  0.278998   \n",
       "..                   ...             ...       ...       ...  ...       ...   \n",
       "152                    0            28.0  0.087269  0.218513  ...  0.087269   \n",
       "153                    4            30.0  0.302879  0.189595  ...  0.302879   \n",
       "154                    0            29.0  0.000000  0.129056  ...  0.000000   \n",
       "155                   16            26.0  0.438701  0.366155  ...  0.438701   \n",
       "156                   14            28.0  0.141409  0.672741  ...  0.141409   \n",
       "\n",
       "         er_y      in_y      is_y      it_y      of_y      on_y  second_y  \\\n",
       "0    0.220946  0.051420  0.278501  0.174735  0.205679  0.183324  0.053809   \n",
       "1    0.284675  0.000000  0.239220  0.000000  0.000000  0.354301  0.415974   \n",
       "2    0.081865  0.076209  0.343969  0.086324  0.152417  0.339627  0.000000   \n",
       "3    0.141591  0.131807  0.475932  0.074651  0.197711  0.176222  0.206896   \n",
       "4    0.523938  0.162578  0.000000  0.184158  0.650314  0.000000  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "152  0.218513  0.101707  0.275434  0.230414  0.305121  0.090652  0.000000   \n",
       "153  0.189595  0.176495  0.424860  0.266562  0.176495  0.104874  0.123129   \n",
       "154  0.129056  0.240276  0.433797  0.272169  0.360414  0.000000  0.000000   \n",
       "155  0.366155  0.000000  0.000000  0.000000  0.170427  0.151904  0.178345   \n",
       "156  0.672741  0.164804  0.148769  0.149343  0.263687  0.117513  0.034492   \n",
       "\n",
       "        the_y      to_y  \n",
       "0    0.812166  0.178732  \n",
       "1    0.550749  0.230284  \n",
       "2    0.633526  0.463567  \n",
       "3    0.547861  0.400884  \n",
       "4    0.405457  0.000000  \n",
       "..        ...       ...  \n",
       "152  0.760947  0.353527  \n",
       "153  0.635791  0.357865  \n",
       "154  0.599229  0.417592  \n",
       "155  0.708386  0.296197  \n",
       "156  0.575411  0.200497  \n",
       "\n",
       "[157 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load text files and clean content\n",
    "texts = []\n",
    "record_ids = results_df['Record-ID'].tolist()\n",
    "for record_id in record_ids:\n",
    "    text_path = f'{folder_path}/{record_id}/{record_id}__CTD.txt'\n",
    "    texts.append(read_and_clean_text(text_path))\n",
    "\n",
    "# Calculate TF-IDF for the cleaned texts\n",
    "vectorizer = TfidfVectorizer(max_features = 10) # Limit to top 10 frequent words tfidf_matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Integrate TF-IDF values into the DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "tfidf_df['Record-ID'] = results_df['Record-ID']\n",
    "results_df = pd.merge(results_df, tfidf_df, on = 'Record-ID')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2584d137-c41d-468a-9bed-8be2a152ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Calculation_of_TF_IDF.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064004c4-960c-4754-b7c5-22f953953d4f",
   "metadata": {},
   "source": [
    "## Calculate the missing converted MMSEs on behalf of TF and IDF using bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b387ebc-0857-4c01-a8d8-ac04f69538e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset for BERT\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, targets = None, tokenizer = None, max_len = 512):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            pad_to_max_length = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt',\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids'].squeeze()\n",
    "        mask = inputs['attention_mask'].squeeze()\n",
    "\n",
    "        if self.targets is not None:\n",
    "            target = torch.tensor(self.targets[index], dtype = torch.float)\n",
    "            return { 'ids': ids, 'mask': mask, 'target': target }\n",
    "        else:\n",
    "            return { 'ids': ids, 'mask': mask }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d75d3420-e0b2-46cf-96da-d4dffce1b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the BERT model\n",
    "def train_model(train_dataset, model, tokenizer, device, learning_rate = 1e-5, epochs = 3):\n",
    "        train_loader = DataLoader(train_dataset, batch_size = 4, shuffle = True)\n",
    "        model.train()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch in train_loader:\n",
    "                ids = batch['ids'].to(device)\n",
    "                mask = batch['mask'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                outputs = model(input_ids = ids, attention_mask = mask)[0]\n",
    "                optimizer.zero_grad()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b740e-7a50-4eef-9010-25d5132db246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\BenLa\\miniconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\BenLa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\BenLa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Prepare training data\n",
    "train_texts = results_df[~results_df['Converted-MMSE'].isna()]['Record-ID'].apply(lambda x: read_and_clean_text(f'{folder_path}/{x}/{x}__CTD.txt')).tolist()\n",
    "train_targets = results_df[~results_df['Converted-MMSE'].isna()]['Converted-MMSE'].tolist()\n",
    "train_dataset = CustomDataset(train_texts, train_targets, tokenizer)\n",
    "\n",
    "# Train the BERT model\n",
    "model = train_model(train_dataset, model, tokenizer, device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39f3df-a059-4915-bda3-c7a23fecfc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict MMSE for missing values\n",
    "test_texts = results_df[results_df['Converted-MMSE'].isna()]['Record-ID'].apply(lambda x: read_and_clean_text(f'{folder_path}/{x}/{x}__CTD.txt')).tolist()\n",
    "test_dataset = CustomDataset(test_texts, tokenizer = tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 4, shuffle = False)\n",
    "\n",
    "model.eval()\n",
    "predicted_mmse = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    ids = batch['ids'].to(device)\n",
    "    mask = batch['mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids = ids, attention_mask = mask)[0]\n",
    "    predicted_mmse.extend(outputs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97cee9d-e7c9-43cd-819c-b87c87b89505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DataFrame with the predicted MMSE values\n",
    "results_df.loc[results_df['Converted-MMSE'].isna(), 'Converted-MMSE'] = predicted_mmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084c8f0-82b5-48e0-b96f-4812c2023be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a751e0d-5c08-4ab5-861d-e28380199b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichere das Ergebnis\n",
    "results_df.to_csv(\"final_results.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
