{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93293cee-ea69-4d90-9554-885e5e09db8d",
   "metadata": {},
   "source": [
    "# Dementia Detection with MobileNet_v2\n",
    "\n",
    "This notebook trains a machine learning system to detect dementia using the **MobileNet_v2** architecture. The training is based on images of spectrograms created in a separate notebook: `image_creator.ipynb`. \n",
    "\n",
    "## Data Source\n",
    "\n",
    "The dataset used for training and testing is the **PROCESS-V1** dataset, which can be downloaded here:  \n",
    "[Download PROCESS-V1 Dataset](https://syncandshare.lrz.de/getlink/fiSPLrnFVFo3DvWqXkLGdY/PROCESS-V1_test.zip)\n",
    "\n",
    "- Only fully labeled data from the dataset is used for image grouping.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. **Spectrogram Generation**:  \n",
    "   Spectrograms are pre-generated in `image_creator.ipynb`.\n",
    "\n",
    "2. **Training**:  \n",
    "   - The MobileNet_v2 model is fine-tuned for dementia detection. \n",
    "   - The notebook includes versions for:\n",
    "     - **2-class classification** (e.g., dementia vs. non-dementia).\n",
    "     - **3-class classification** based on the original dataset labels.\n",
    "   - Fast training is facilitated by using an NVIDIA graphics card with a **2000 Series or newer**.\n",
    "\n",
    "3. **Results Verification**:  \n",
    "   - Model interpretability is verified using **LIME (Local Interpretable Model-agnostic Explanations)**.\n",
    "   - A **confusion matrix** is generated to evaluate classification performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9fdc6d1-a393-471c-b2e3-3f70bf3fdd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 16 21:28:08 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 40%   30C    P2             27W /  130W |    1869MiB /   8192MiB |      7%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1920    C+G   ...\\Programs\\signal-desktop\\Signal.exe      N/A      |\n",
      "|    0   N/A  N/A      3032    C+G   ...n\\131.0.2903.112\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A      6056    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A      7208    C+G   ...s (x86)\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A      9400    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10936    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12164    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12584    C+G   ....0_x64__8wekyb3d8bbwe\\XboxPcApp.exe      N/A      |\n",
      "|    0   N/A  N/A     13548    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13784    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     14732    C+G   ...les\\AMD\\CNext\\CNext\\AMDRSSrcExt.exe      N/A      |\n",
      "|    0   N/A  N/A     15468    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16340    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     17084      C   ...vVirtualCamera\\NVIDIA Broadcast.exe      N/A      |\n",
      "|    0   N/A  N/A     17952    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n",
      "|    0   N/A  N/A     18192    C+G   ...al\\Discord\\app-1.0.9177\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     18988    C+G   ...nzyj5cx40ttqa\\iCloud\\iCloudHome.exe      N/A      |\n",
      "|    0   N/A  N/A     19100    C+G   ...\\AMD\\CNext\\CNext\\RadeonSoftware.exe      N/A      |\n",
      "|    0   N/A  N/A     19232    C+G   ...\\Programs\\signal-desktop\\Signal.exe      N/A      |\n",
      "|    0   N/A  N/A     20540    C+G   C:\\Windows\\System32\\mmgaserver.exe          N/A      |\n",
      "|    0   N/A  N/A     21092    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     21420    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     22080      C   C:\\Users\\Peter\\miniconda3\\python.exe        N/A      |\n",
      "|    0   N/A  N/A     23200    C+G   ...s (x86)\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     24368    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A     25040    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     25192    C+G   ...ejd91yc\\AdobeNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A     26088    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Requirement already satisfied: lime in c:\\users\\peter\\miniconda3\\lib\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (1.26.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (1.13.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (4.66.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (1.5.2)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (0.24.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2.36.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2024.9.20)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (23.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\peter\\miniconda3\\lib\\site-packages (from tqdm->lime) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "#!pip install imbalanced-learn\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f86164e-38f2-4d07-84a6-7926b2e9fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m    128\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectrogram_classifier_20.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 102\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[0;32m     99\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    100\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 102\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define data directories\n",
    "data_dir = r\"F:\\Peter\\ML_exp\\PROCESS-V1\\Spectrograms\"  # Replace with the path to the spectrograms\n",
    "healthy_dir = os.path.join(data_dir, \"Healthy\")\n",
    "not_healthy_dir = os.path.join(data_dir, \"Not Healthy\")\n",
    "\n",
    "# Define transformations for the training and validation datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "def cutmix(data, targets, alpha=1.0):\n",
    "    \"\"\"Apply CutMix augmentation on a batch of data and targets.\"\"\"\n",
    "    indices = torch.randperm(data.size(0))  # Shuffle batch indices\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    # Sample the lambda parameter from a Beta distribution\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    H, W = data.size(2), data.size(3)\n",
    "\n",
    "    # Compute the bounding box\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # Randomly select the center of the bounding box\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    # Mix the images and adjust the labels\n",
    "    data[:, :, bby1:bby2, bbx1:bbx2] = shuffled_data[:, :, bby1:bby2, bbx1:bbx2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (H * W))\n",
    "\n",
    "    return data, targets, shuffled_targets, lam\n",
    "\n",
    "\n",
    "# Prepare datasets and split into train/validation sets\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "class_names = dataset.classes  # ['Healthy', 'Not Healthy']\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the model (using a pre-trained ResNet)\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # Updated weights usage\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))  # 2 classes: Healthy and Not Healthy\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, average='binary'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return f1, precision, recall\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Mixed precision\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=20)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"spectrogram_classifier_20.pth\")\n",
    "\n",
    "\n",
    "print(\"Model saved as spectrogram_classifier_20.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81e207a-c74b-41a0-8c31-9c361c790760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model saved as final_spectrogram_classifier_15.pth\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define data directories\n",
    "data_dir = r\"F:\\Peter\\ML_exp\\PROCESS-V1\\Spectrograms\"  # Replace with the path to the spectrograms\n",
    "healthy_dir = os.path.join(data_dir, \"Healthy\")\n",
    "not_healthy_dir = os.path.join(data_dir, \"Not Healthy\")\n",
    "\n",
    "# Define transformations for the training and validation datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to optimize memory usage\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Prepare datasets and split into train/validation sets\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "class_names = dataset.classes  # ['Healthy', 'Not Healthy']\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the model (using a pre-trained ResNet)\n",
    "from torchvision.models import mobilenet_v2\n",
    "model = mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model.last_channel\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Calculate metrics function\n",
    "def calculate_metrics(y_true, y_pred, average='binary'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return f1, precision, recall\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cutmix(data, targets, alpha=1.0):\n",
    "    \"\"\"Apply CutMix augmentation on a batch of data and targets.\"\"\"\n",
    "    indices = torch.randperm(data.size(0))  # Shuffle batch indices\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    # Sample the lambda parameter from a Beta distribution\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    H, W = data.size(2), data.size(3)\n",
    "\n",
    "    # Compute the bounding box\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # Randomly select the center of the bounding box\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    # Mix the images and adjust the labels\n",
    "    data[:, :, bby1:bby2, bbx1:bbx2] = shuffled_data[:, :, bby1:bby2, bbx1:bbx2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (H * W))\n",
    "\n",
    "    return data, targets, shuffled_targets, lam\n",
    "\n",
    "\n",
    "# Training and Validation function\n",
    "# Define the updated train_model function with advanced overfitting detection\n",
    "def train_model_with_smote_and_explainability(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):\n",
    "    best_val_f1 = 0.0\n",
    "    lr = 0.0001\n",
    "    alpha=1.0\n",
    "    weight_decay = 1e-4\n",
    "    overfitting_threshold = 3  # Number of consecutive epochs of overfitting to trigger adjustments\n",
    "    overfitting_epochs = 0\n",
    "\n",
    "    # Track historical loss differences for smarter overfitting detection\n",
    "    loss_differences = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}, Learning Rate: {lr:.6f}, Weight Decay: {weight_decay:.6f}\")\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Apply CutMix\n",
    "            inputs, targets_a, targets_b, lam = cutmix(inputs, labels, alpha=alpha)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (lam * predicted.eq(targets_a).sum().item() +\n",
    "                              (1 - lam) * predicted.eq(targets_b).sum().item())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_labels, all_preds = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        # Calculate metrics\n",
    "        val_f1, val_precision, val_recall = calculate_metrics(all_labels, all_preds)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Val F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation F1 Score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Best model saved!\")\n",
    "\n",
    "        # --- Smarter Overfitting Detection ---\n",
    "        loss_diff = val_loss - train_loss\n",
    "        acc_diff = train_acc - val_acc\n",
    "        loss_differences.append(loss_diff)\n",
    "\n",
    "        # Check rolling average of loss differences\n",
    "        if len(loss_differences) > 3:\n",
    "            rolling_avg_loss_diff = np.mean(loss_differences[-3:])\n",
    "            if rolling_avg_loss_diff > 0.1 and acc_diff > 0.1:\n",
    "                overfitting_epochs += 1\n",
    "                print(f\"Overfitting detected (Rolling Loss Diff: {rolling_avg_loss_diff:.4f}).\")\n",
    "            else:\n",
    "                overfitting_epochs = 0\n",
    "\n",
    "        if overfitting_epochs >= overfitting_threshold:\n",
    "            print(\"Overfitting persists. Adjusting learning rate and weight decay.\")\n",
    "            lr *= 0.5\n",
    "            weight_decay *= 0.9\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "                param_group['weight_decay'] = weight_decay\n",
    "            overfitting_epochs = 0  # Reset counter\n",
    "\n",
    "    # Explain model predictions with LIME after training\n",
    "    explain_with_lime(model, val_loader, device)\n",
    "\n",
    "# SMOTE: Handle imbalanced datasets\n",
    "def apply_smote(train_loader):\n",
    "    smote = SMOTE()\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        train_data.extend(inputs.view(inputs.size(0), -1).numpy())\n",
    "        train_labels.extend(labels.numpy())\n",
    "\n",
    "    train_data_smote, train_labels_smote = smote.fit_resample(np.array(train_data), np.array(train_labels))\n",
    "    print(\"SMOTE applied. Resampled dataset size:\", len(train_labels_smote))\n",
    "\n",
    "    return train_data_smote, train_labels_smote\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess dataset with SMOTE\n",
    "#train_data_smote, train_labels_smote = apply_smote(train_loader)\n",
    "\n",
    "# Train model with the new improvements\n",
    "#train_model_with_smote_and_explainability(model, criterion, optimizer, train_loader, val_loader, device, epochs=15)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "#train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=15)\n",
    "\n",
    "# Save the final trained model\n",
    "#torch.save(model.state_dict(), \"final_spectrogram_classifier_15.pth\")\n",
    "print(\"Model saved as final_spectrogram_classifier_15.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9a0e3-8400-4540-9480-26d41b30ab88",
   "metadata": {},
   "source": [
    "**Now with 3 classes (based on dataset)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7479e3a-d094-4564-9df5-8ffa352f883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# LIME: Explain predictions\n",
    "def explain_with_lime(model, val_loader, device):\n",
    "    explainer = LimeImageExplainer()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            sample_image = inputs[0].cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "            explanation = explainer.explain_instance(\n",
    "                image=sample_image,\n",
    "                classifier_fn=lambda x: model(torch.tensor(x.transpose(0, 3, 1, 2)).float().to(device)).detach().cpu().numpy(),\n",
    "                top_labels=2,\n",
    "                hide_color=0,\n",
    "                num_samples=1000\n",
    "            )\n",
    "\n",
    "            temp, mask = explanation.get_image_and_mask(\n",
    "                label=1,  # Assuming class 1 is \"Not Healthy\"\n",
    "                positive_only=True,\n",
    "                num_features=10,\n",
    "                hide_rest=False\n",
    "            )\n",
    "\n",
    "            lime_image = mark_boundaries(temp, mask)\n",
    "            plt.imshow(lime_image)\n",
    "            plt.title(\"LIME Explanation\")\n",
    "            plt.show()\n",
    "            break  # Explain one sample for demonstration\n",
    "# Function to display confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap='viridis', xticks_rotation='vertical')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Training and validation function with confusion matrix\n",
    "def train_model_with_confusion_matrix(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):\n",
    "    best_val_f1 = 0.0\n",
    "    lr = 0.0001\n",
    "    alpha = 1.0\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}, Learning Rate: {lr:.6f}, Weight Decay: {weight_decay:.6f}\")\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Apply CutMix\n",
    "            inputs, targets_a, targets_b, lam = cutmix(inputs, labels, alpha=alpha)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (lam * predicted.eq(targets_a).sum().item() +\n",
    "                              (1 - lam) * predicted.eq(targets_b).sum().item())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_labels, all_preds = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        # Calculate metrics\n",
    "        val_f1, val_precision, val_recall = calculate_metrics(all_labels, all_preds)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Val F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation F1 Score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Best model saved!\")\n",
    "\n",
    "    # Plot confusion matrix for validation results\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181a743-d694-4f41-b3c7-2d7782c0ce56",
   "metadata": {},
   "source": [
    "# With Cross Validation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757cad4a-193e-42d5-80fa-971d77182fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db7210be-7582-4416-88de-b69c50651433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Function to plot training and validation loss and accuracy\n",
    "def plot_training_progress(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Function to display confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap='viridis', xticks_rotation='vertical')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Training and validation function with metric tracking, visualization, and early stopping\n",
    "def train_model_with_plots_and_explainability(model, criterion, optimizer, train_loader, val_loader, device, epochs=10, patience=2):\n",
    "    best_val_f1 = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    lr = 0.0001\n",
    "    alpha = 1.0\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}, Learning Rate: {lr:.6f}, Weight Decay: {weight_decay:.6f}\")\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Apply CutMix\n",
    "            inputs, targets_a, targets_b, lam = cutmix(inputs, labels, alpha=alpha)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (lam * predicted.eq(targets_a).sum().item() +\n",
    "                              (1 - lam) * predicted.eq(targets_b).sum().item())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_labels, all_preds = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Calculate metrics\n",
    "        val_f1, val_precision, val_recall = calculate_metrics(all_labels, all_preds)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Val F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation F1 Score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Best model saved!\")\n",
    "\n",
    "        # Early stopping based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "        else:\n",
    "            patience_counter += 1  # Increment patience counter\n",
    "            print(f\"Early stopping patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        print(\"Unique classes in labels:\", np.unique(all_labels))\n",
    "        print(\"Unique classes in predictions:\", np.unique(all_preds))\n",
    "\n",
    "        # Plot confusion matrix for validation results\n",
    "        if epoch == epochs - 1 or patience_counter >= patience:  # Plot confusion matrix after last epoch or early stop\n",
    "            print(\"\\nConfusion Matrix:\")\n",
    "            plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "\n",
    "    # Plot training progress\n",
    "    plot_training_progress(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "    # Explain model predictions with LIME\n",
    "    explain_with_lime(model, val_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77856497-f233-4851-a4ff-e6c438680d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# Arrays to store results\n",
    "\n",
    "def train_with_cross_validation(dataset, model, criterion, optimizer, device, epochs=10, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "\n",
    "        # Create data loaders for this fold\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize model weights\n",
    "        model.apply(reset_weights)\n",
    "\n",
    "        # Train and evaluate the model for this fold\n",
    "        train_model_with_plots_and_explainability(model, criterion, optimizer, train_loader, val_loader, device, epochs=epochs)\n",
    "\n",
    "        # Load the best model for evaluation\n",
    "        model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        val_correct, val_total, all_labels, all_preds = 0, 0, [], []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_f1, val_precision, val_recall = calculate_metrics(all_labels, all_preds)\n",
    "        fold_results.append((val_acc, val_f1, val_precision, val_recall))\n",
    "\n",
    "        print(f\"Fold {fold + 1} Results - Accuracy: {val_acc:.4f}, F1: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n",
    "\n",
    "    # Average results across folds\n",
    "    avg_results = {\n",
    "        \"Accuracy\": sum(result[0] for result in fold_results) / n_splits,\n",
    "        \"F1\": sum(result[1] for result in fold_results) / n_splits,\n",
    "        \"Precision\": sum(result[2] for result in fold_results) / n_splits,\n",
    "        \"Recall\": sum(result[3] for result in fold_results) / n_splits,\n",
    "    }\n",
    "    print(\"\\n--- Cross-Validation Results ---\")\n",
    "    print(avg_results)\n",
    "    # Calculate and display argmax, argmin, mean, and standard deviation for each metric\n",
    "    fold_results = np.array(fold_results)\n",
    "    metrics = ['Accuracy', 'F1', 'Precision', 'Recall']\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        max_value = np.max(fold_results[:, i])\n",
    "        min_value = np.min(fold_results[:, i])\n",
    "        mean_value = np.mean(fold_results[:, i])\n",
    "        std_value = np.std(fold_results[:, i])\n",
    "        max_fold = np.argmax(fold_results[:, i]) + 1  # 0-based to 1-based\n",
    "        min_fold = np.argmin(fold_results[:, i]) + 1\n",
    "\n",
    "        print(f\"\\n{metric} - Max: {max_value:.4f} (Fold {max_fold}), \"\n",
    "              f\"Min: {min_value:.4f} (Fold {min_fold}), \"\n",
    "              f\"Mean: {mean_value:.4f}, Std Dev: {std_value:.4f}\")\n",
    "    return avg_results\n",
    "\n",
    "# Function to reset model weights (useful for each fold)\n",
    "def reset_weights(layer):\n",
    "    if hasattr(layer, \"reset_parameters\"):\n",
    "        layer.reset_parameters()\n",
    "\n",
    "# Example usage:\n",
    "#train_with_cross_validation(dataset, model, criterion, optimizer, device, epochs=2, n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84564c-dc49-4cb5-9dda-a67715cad5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Detected classes: ['Dementia', 'HC', 'MCI'], Number of classes: 3\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "\n",
      "Epoch 1/30, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.9689, Train Acc: 0.4536\n",
      "Val Loss: 0.9748, Val Acc: 0.4617\n",
      "Val F1 Score: 0.3334, Precision: 0.3902, Recall: 0.4617\n",
      "Best model saved!\n",
      "Unique classes in labels: [0 1 2]\n",
      "Unique classes in predictions: [1 2]\n",
      "\n",
      "Epoch 2/30, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.9630, Train Acc: 0.4635\n",
      "Val Loss: 0.9534, Val Acc: 0.4536\n",
      "Val F1 Score: 0.4272, Precision: 0.4037, Recall: 0.4536\n",
      "Best model saved!\n",
      "Unique classes in labels: [0 1 2]\n",
      "Unique classes in predictions: [1 2]\n",
      "\n",
      "Epoch 3/30, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.9589, Train Acc: 0.4803\n",
      "Val Loss: 0.9480, Val Acc: 0.4787\n",
      "Val F1 Score: 0.4473, Precision: 0.4323, Recall: 0.4787\n",
      "Best model saved!\n",
      "Unique classes in labels: [0 1 2]\n",
      "Unique classes in predictions: [1 2]\n",
      "\n",
      "Epoch 4/30, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.9560, Train Acc: 0.4815\n",
      "Val Loss: 0.9419, Val Acc: 0.4862\n",
      "Val F1 Score: 0.4376, Precision: 0.4574, Recall: 0.4862\n",
      "Unique classes in labels: [0 1 2]\n",
      "Unique classes in predictions: [1 2]\n",
      "\n",
      "Epoch 5/30, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.9511, Train Acc: 0.4890\n",
      "Val Loss: 0.9379, Val Acc: 0.4931\n",
      "Val F1 Score: 0.4637, Precision: 0.4420, Recall: 0.4931\n",
      "Best model saved!\n",
      "Unique classes in labels: [0 1 2]\n",
      "Unique classes in predictions: [1 2]\n",
      "\n",
      "Epoch 6/30, Learning Rate: 0.000100, Weight Decay: 0.000100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define data directories\n",
    "# Define data directories (list of folders)\n",
    "data_dirs = [\n",
    "    \"F://Peter//ML_exp//PROCESS-V1//Spectrograms_3\",\n",
    "    \"F://Peter//ML_exp//PROCESS-V1//spectograms_3_10s\",\n",
    "    \"F://Peter//ML_exp//PROCESS-V1//spectograms_3_20s\"\n",
    "]\n",
    "\n",
    "# Dynamically get the list of classes based on the first folder\n",
    "# Assumes all folders have the same class structure\n",
    "class_names = sorted(next(os.walk(data_dirs[0]))[1])\n",
    "num_classes = len(class_names)\n",
    "print(f\"Detected classes: {class_names}, Number of classes: {num_classes}\")\n",
    "\n",
    "# Define transformations for the training and validation datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to optimize memory usage\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Prepare datasets from multiple folders\n",
    "datasets_list = [datasets.ImageFolder(data_dir, transform=transform) for data_dir in data_dirs]\n",
    "\n",
    "# Combine all datasets into one\n",
    "combined_dataset = ConcatDataset(datasets_list)\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_size = int(0.8 * len(combined_dataset))\n",
    "val_size = len(combined_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "# Prepare data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the model (using a pre-trained MobileNetV2)\n",
    "from torchvision.models import mobilenet_v2\n",
    "model = mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model.last_channel\n",
    "\n",
    "# Modify the final layer to match the number of classes\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Calculate metrics function\n",
    "def calculate_metrics(y_true, y_pred, average='weighted'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    precision = precision_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    return f1, precision, recall\n",
    "\n",
    "# SMOTE and other training functions remain unchanged...\n",
    "train_with_cross_validation(combined_dataset, model, criterion, optimizer, device, epochs=30, n_splits=5)\n",
    "\n",
    "# Train the model with the new functionality\n",
    "# train_model_with_plots_and_explainability(\n",
    "#    model, criterion, optimizer, train_loader, val_loader, device, epochs=15\n",
    "#)\n",
    "# Train the model with confusion matrix functionality / updated \n",
    "#train_model_with_confusion_matrix(\n",
    "#    model, criterion, optimizer, train_loader, val_loader, device, epochs=20\n",
    "#)\n",
    "\n",
    "# Get the current date and format it\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create the filename with the current date\n",
    "filename = f\"final_spectrogram_classifier_dynamic_{current_date}.pth\"\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), filename)\n",
    "print(\"Model saved as final_spectrogram_classifier_dynamic.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06adce-62e6-4649-8e08-e6e8531afd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "With 3 Different Spectogramm Sizes Validation loss never drops below 0.7 ....\n",
    "\n",
    "The classifier trained and validated on a larger dataset shows performance trends similar to the earlier results, albeit with slight improvements in some metrics, likely due to the increased data size. Below is a detailed analysis:\n",
    "Key Observations:\n",
    "General Trends Across Folds:\n",
    "\n",
    "    Training Loss and Accuracy:\n",
    "        Training loss decreases steadily across epochs in all folds, suggesting effective learning.\n",
    "        Training accuracy improves consistently, reaching ~50 – 52% in later epochs.\n",
    "\n",
    "    Validation Metrics:\n",
    "        Validation accuracy averages around 51%, with slight fluctuations across folds.\n",
    "        Validation F1 scores range between ~0.43 - 0.50, showing moderate improvements over epochs.\n",
    "\n",
    "    Best Model Checkpoint:\n",
    "        The model is saved when validation F1 or accuracy peaks, ensuring the best-performing model on the validation set is preserved.\n",
    "\n",
    "Per Fold Summary:\n",
    "Fold\tAccuracy\tF1 Score\tPrecision\tRecall\n",
    "Fold 1\t0.5298\t0.4966\t0.4698\t0.5298\n",
    "Fold 2\t0.5118\t0.4860\t0.5611\t0.5118\n",
    "Fold 3\t0.5394\t0.5074\t0.4826\t0.5394\n",
    "Fold 4\t0.4707\t0.4379\t0.4207\t0.4707\n",
    "Fold 5\t0.5045\t0.4770\t0.4523\t0.5045\n",
    "Overall Cross-Validation Results:\n",
    "Metric\tValue\n",
    "Accuracy\t0.5113\n",
    "F1 Score\t0.4810\n",
    "Precision\t0.4773\n",
    "Recall\t0.5113\n",
    "\n",
    "    Accuracy is consistent with the validation performance seen in individual folds.\n",
    "    F1 Score suggests moderate balance between precision and recall, with slight improvements over the smaller dataset.\n",
    "    Precision and recall remain comparable, indicating a balanced approach to predictions for the three classes.\n",
    "\n",
    "Analysis:\n",
    "Impact of Larger Dataset:\n",
    "\n",
    "    Improvements:\n",
    "        Validation metrics, particularly F1 scores and recall, have improved slightly over the smaller dataset, showcasing the model's enhanced generalization capabilities.\n",
    "        Consistent performance trends across folds suggest the model benefits from the larger dataset by learning more representative patterns.\n",
    "    Challenges:\n",
    "        The improvements are incremental, indicating that the model architecture or training approach may still have limitations.\n",
    "        Variability in performance across folds (e.g., Fold 4's lower metrics) hints at possible data imbalance or feature overlap between classes.\n",
    "\n",
    "Precision vs. Recall:\n",
    "\n",
    "    Precision and recall are close, but Fold 2 demonstrates higher precision than recall, potentially indicating a slightly conservative approach in classification for that fold.\n",
    "    The balance between precision and recall suggests that the model avoids excessive bias toward either false positives or false negatives.\n",
    "\n",
    "Recommendations:\n",
    "\n",
    "    Model Enhancements:\n",
    "        Experiment with deeper or more complex architectures to better capture features in the larger dataset.\n",
    "        Use additional regularization techniques to further improve generalization.\n",
    "\n",
    "    Data Analysis:\n",
    "        Investigate potential class imbalances or overlaps in the dataset and apply techniques like oversampling or class weighting if necessary.\n",
    "        Analyze misclassifications to identify specific areas where the model struggles (e.g., confusion between MCI and Dementia).\n",
    "\n",
    "    Data Augmentation:\n",
    "        Introduce augmentation techniques to further enhance the dataset's diversity, potentially boosting performance.\n",
    "\n",
    "    Hyperparameter Tuning:\n",
    "        Experiment with different learning rates, weight decay values, and optimizer settings to optimize convergence and performance.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "The model demonstrates moderate improvement in validation performance with the larger dataset. However, further enhancements in architecture, hyperparameters, or data preprocessing are required to achieve significant gains in distinguishing between the three classes: Dementia, Healthy Control (HC), and Mild Cognitive Impairment (MCI)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c340072-ea7c-4a5c-b2fc-04a2340d8cbe",
   "metadata": {},
   "source": [
    "=> using only 5 s intervalls for images => Key Observations from Each Fold:\n",
    "General Trends Across Folds:\n",
    "\n",
    "    Train Loss and Accuracy:\n",
    "        Train loss decreases steadily across epochs in all folds, indicating the model is learning.\n",
    "        Train accuracy improves consistently, reaching the range of ~0.50 by the final epochs, but starts from a relatively low point (~0.44).\n",
    "\n",
    "    Validation Performance:\n",
    "        Validation accuracy fluctuates but shows gradual improvement across epochs in most folds.\n",
    "        The best validation accuracy ranges from ~0.49 to ~0.53 across folds.\n",
    "        F1 scores improve during the process but remain moderate (~0.45–0.50), with precision and recall values close to each other.\n",
    "\n",
    "    Best Model Saving:\n",
    "        The model is saved based on its best validation metrics, often coinciding with a peak in F1 scores.\n",
    "\n",
    "Specific Metrics:\n",
    "\n",
    "    Confusion Matrices:\n",
    "        Observations like \"Clipping input data to the valid range for imshow\" indicate preprocessing visualizations.\n",
    "        Confusion matrices validate predictions but aren't numerically detailed here.\n",
    "\n",
    "    Fold Summaries:\n",
    "        Fold 1: Accuracy: 0.4916, F1: 0.4530\n",
    "        Fold 2: Accuracy: 0.5309, F1: 0.5061\n",
    "        Fold 3: Accuracy: 0.5045, F1: 0.4637\n",
    "        Fold 4: Accuracy: 0.5034, F1: 0.4727\n",
    "        Fold 5: Accuracy: 0.5191, F1: 0.4858\n",
    "\n",
    "Cross-Validation Results:\n",
    "\n",
    "    Average Metrics:\n",
    "        Accuracy: 0.5099\n",
    "        F1 Score: 0.4763\n",
    "        Precision: 0.4676\n",
    "        Recall: 0.5099\n",
    "\n",
    "Observations:\n",
    "\n",
    "    Performance Consistency:\n",
    "        Accuracy and F1 scores are relatively consistent across folds, indicating stable learning but also exposing room for improvement.\n",
    "\n",
    "    Precision vs. Recall:\n",
    "        Precision and recall values are close, suggesting that the model doesn't significantly favor precision over recall or vice versa, which is suitable for balanced datasets.\n",
    "\n",
    "    Limitations:\n",
    "        Validation metrics indicate moderate performance, suggesting potential challenges in differentiating between the three classes.\n",
    "        Improvements in train accuracy are not fully reflected in validation performance, indicating possible overfitting or suboptimal generalization.\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "    Model Improvements:\n",
    "        Fine-tuning the hyperparameters (learning rate, weight decay).\n",
    "        Exploring more complex architectures or adding regularization to improve generalization.\n",
    "\n",
    "    Data Augmentation:\n",
    "        Enhancing the dataset with augmentation techniques may improve robustness and performance.\n",
    "\n",
    "    Class Imbalance:\n",
    "        Investigate if the dataset is balanced across classes. If not, consider techniques like oversampling or weighted loss functions.\n",
    "\n",
    "    Explainability:\n",
    "        Investigate misclassified examples to identify patterns or common issues (e.g., overlapping features between classes).\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "The model achieves moderate classification performance across all folds, with validation accuracy averaging ~51%. The results suggest that the current approach is a solid starting point but requires further tuning and enhancement for better differentiation among the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6aa4b-4fe8-4bf2-b9bd-6306e8063ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Example model architecture (replace with your own)\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Dummy forward pass\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter search.\n",
    "    Returns: validation F1 score\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Suggest hyperparameters ---\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.2, 1.0)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    epochs = 5  # Keep this short for quick trials; you can adjust as needed.\n",
    "\n",
    "    # --- Build your model ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyModel(num_classes=len(class_names)).to(device)\n",
    "\n",
    "    # Define loss, optimizer, etc.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # --- Tracking metrics ---\n",
    "    best_val_f1 = 0.0\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Apply CutMix (assumed you have this function defined)\n",
    "            inputs, targets_a, targets_b, lam = cutmix(inputs, labels, alpha=alpha)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Compute training loss & accuracy\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (\n",
    "                lam * predicted.eq(targets_a).sum().item()\n",
    "                + (1 - lam) * predicted.eq(targets_b).sum().item()\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_labels, all_preds = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Calculate metrics (assumed you have this function)\n",
    "        val_f1, val_precision, val_recall = calculate_metrics(all_labels, all_preds)\n",
    "\n",
    "        # Save the best model based on validation F1\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "\n",
    "    # Return the best validation F1 of this trial\n",
    "    return best_val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a83f0c-3e56-42ee-9894-d745a3b6ebce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb591a-6099-44c2-94c7-5b30231083f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
