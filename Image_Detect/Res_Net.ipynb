{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fdc6d1-a393-471c-b2e3-3f70bf3fdd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 10 20:10:43 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 41%   25C    P8             10W /  130W |    1545MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2604    C+G   ...\\Programs\\signal-desktop\\Signal.exe      N/A      |\n",
      "|    0   N/A  N/A      9952    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      9968    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A     12388    C+G   ...s (x86)\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     13196    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13800    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     14044    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     15956    C+G   ...s (x86)\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     16428    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17620    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n",
      "|    0   N/A  N/A     17916    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     19272    C+G   ...\\AMD\\CNext\\CNext\\RadeonSoftware.exe      N/A      |\n",
      "|    0   N/A  N/A     19524    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19692    C+G   ...al\\Discord\\app-1.0.9173\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     19864    C+G   ...ejd91yc\\AdobeNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A     20052    C+G   ...ces\\Razer Central\\Razer Central.exe      N/A      |\n",
      "|    0   N/A  N/A     20736    C+G   ...on\\HEX\\Creative Cloud UI Helper.exe      N/A      |\n",
      "|    0   N/A  N/A     21960    C+G   ...eUS\\Todo Backup\\bin\\TrayProcess.exe      N/A      |\n",
      "|    0   N/A  N/A     23980    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     25520    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     25652    C+G   ...on\\131.0.2903.70\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     27448    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     30172    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     30848    C+G   ...les\\AMD\\CNext\\CNext\\AMDRSSrcExt.exe      N/A      |\n",
      "|    0   N/A  N/A     30952    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Requirement already satisfied: lime in c:\\users\\peter\\miniconda3\\lib\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (1.26.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (1.13.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (4.66.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (1.5.2)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from lime) (0.24.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2.36.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2024.9.20)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (23.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\peter\\miniconda3\\lib\\site-packages (from tqdm->lime) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peter\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "#!pip install imbalanced-learn\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86164e-38f2-4d07-84a6-7926b2e9fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define data directories\n",
    "data_dir = r\"F:\\Peter\\ML_exp\\PROCESS-V1\\Spectrograms\"  # Replace with the path to the spectrograms\n",
    "healthy_dir = os.path.join(data_dir, \"Healthy\")\n",
    "not_healthy_dir = os.path.join(data_dir, \"Not Healthy\")\n",
    "\n",
    "# Define transformations for the training and validation datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Prepare datasets and split into train/validation sets\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "class_names = dataset.classes  # ['Healthy', 'Not Healthy']\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the model (using a pre-trained ResNet)\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # Updated weights usage\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))  # 2 classes: Healthy and Not Healthy\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, average='binary'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return f1, precision, recall\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Mixed precision\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=20)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"spectrogram_classifier_20.pth\")\n",
    "\n",
    "\n",
    "print(\"Model saved as spectrogram_classifier_20.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e207a-c74b-41a0-8c31-9c361c790760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "SMOTE applied. Resampled dataset size: 4080\n",
      "\n",
      "Epoch 1/15, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.6428, Train Acc: 0.6458\n",
      "Val Loss: 0.5591, Val Acc: 0.7081\n",
      "Val F1 Score: 0.7166, Precision: 0.7621, Recall: 0.6762\n",
      "Best model saved!\n",
      "\n",
      "Epoch 2/15, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.4800, Train Acc: 0.7717\n",
      "Val Loss: 0.4671, Val Acc: 0.7785\n",
      "Val F1 Score: 0.7950, Precision: 0.8033, Recall: 0.7869\n",
      "Best model saved!\n",
      "\n",
      "Epoch 3/15, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.3505, Train Acc: 0.8478\n",
      "Val Loss: 0.4394, Val Acc: 0.8020\n",
      "Val F1 Score: 0.8210, Precision: 0.8104, Recall: 0.8320\n",
      "Best model saved!\n",
      "\n",
      "Epoch 4/15, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.2479, Train Acc: 0.8993\n",
      "Val Loss: 0.5090, Val Acc: 0.7942\n",
      "Val F1 Score: 0.8182, Precision: 0.7901, Recall: 0.8484\n",
      "Overfitting detected (Rolling Loss Diff: 0.1124).\n",
      "\n",
      "Epoch 5/15, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.1699, Train Acc: 0.9292\n",
      "Val Loss: 0.5687, Val Acc: 0.7998\n",
      "Val F1 Score: 0.8212, Precision: 0.8012, Recall: 0.8422\n",
      "Best model saved!\n",
      "Overfitting detected (Rolling Loss Diff: 0.2496).\n",
      "\n",
      "Epoch 6/15, Learning Rate: 0.000100, Weight Decay: 0.000100\n",
      "Train Loss: 0.1526, Train Acc: 0.9398\n",
      "Val Loss: 0.5634, Val Acc: 0.8098\n",
      "Val F1 Score: 0.8211, Precision: 0.8442, Recall: 0.7992\n",
      "Overfitting detected (Rolling Loss Diff: 0.3569).\n",
      "Overfitting persists. Adjusting learning rate and weight decay.\n",
      "\n",
      "Epoch 7/15, Learning Rate: 0.000050, Weight Decay: 0.000090\n",
      "Train Loss: 0.0922, Train Acc: 0.9636\n",
      "Val Loss: 0.4963, Val Acc: 0.8434\n",
      "Val F1 Score: 0.8583, Precision: 0.8480, Recall: 0.8689\n",
      "Best model saved!\n",
      "Overfitting detected (Rolling Loss Diff: 0.4046).\n",
      "\n",
      "Epoch 8/15, Learning Rate: 0.000050, Weight Decay: 0.000090\n",
      "Train Loss: 0.0568, Train Acc: 0.9813\n",
      "Val Loss: 0.5674, Val Acc: 0.8311\n",
      "Val F1 Score: 0.8382, Precision: 0.8787, Recall: 0.8012\n",
      "Overfitting detected (Rolling Loss Diff: 0.4418).\n",
      "\n",
      "Epoch 9/15, Learning Rate: 0.000050, Weight Decay: 0.000090\n",
      "Train Loss: 0.0403, Train Acc: 0.9849\n",
      "Val Loss: 0.5884, Val Acc: 0.8367\n",
      "Val F1 Score: 0.8519, Precision: 0.8434, Recall: 0.8607\n",
      "Overfitting detected (Rolling Loss Diff: 0.4876).\n",
      "Overfitting persists. Adjusting learning rate and weight decay.\n",
      "\n",
      "Epoch 10/15, Learning Rate: 0.000025, Weight Decay: 0.000081\n",
      "Train Loss: 0.0353, Train Acc: 0.9863\n",
      "Val Loss: 0.5760, Val Acc: 0.8456\n",
      "Val F1 Score: 0.8639, Precision: 0.8327, Recall: 0.8975\n",
      "Best model saved!\n",
      "Overfitting detected (Rolling Loss Diff: 0.5331).\n",
      "\n",
      "Epoch 11/15, Learning Rate: 0.000025, Weight Decay: 0.000081\n",
      "Train Loss: 0.0197, Train Acc: 0.9955\n",
      "Val Loss: 0.5662, Val Acc: 0.8412\n",
      "Val F1 Score: 0.8515, Precision: 0.8697, Recall: 0.8340\n",
      "Overfitting detected (Rolling Loss Diff: 0.5451).\n",
      "\n",
      "Epoch 12/15, Learning Rate: 0.000025, Weight Decay: 0.000081\n",
      "Train Loss: 0.0167, Train Acc: 0.9947\n",
      "Val Loss: 0.5952, Val Acc: 0.8434\n",
      "Val F1 Score: 0.8523, Precision: 0.8783, Recall: 0.8279\n",
      "Overfitting detected (Rolling Loss Diff: 0.5552).\n",
      "Overfitting persists. Adjusting learning rate and weight decay.\n",
      "\n",
      "Epoch 13/15, Learning Rate: 0.000013, Weight Decay: 0.000073\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define data directories\n",
    "data_dir = r\"F:\\Peter\\ML_exp\\PROCESS-V1\\Spectrograms\"  # Replace with the path to the spectrograms\n",
    "healthy_dir = os.path.join(data_dir, \"Healthy\")\n",
    "not_healthy_dir = os.path.join(data_dir, \"Not Healthy\")\n",
    "\n",
    "# Define transformations for the training and validation datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to optimize memory usage\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Prepare datasets and split into train/validation sets\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "class_names = dataset.classes  # ['Healthy', 'Not Healthy']\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the model (using a pre-trained ResNet)\n",
    "from torchvision.models import mobilenet_v2\n",
    "model = mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model.last_channel\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Calculate metrics function\n",
    "def calculate_metrics(y_true, y_pred, average='binary'):\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return f1, precision, recall\n",
    "\n",
    "# Training and Validation function\n",
    "# Define the updated train_model function with advanced overfitting detection\n",
    "def train_model_with_smote_and_explainability(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):\n",
    "    best_val_f1 = 0.0\n",
    "    lr = 0.0001\n",
    "    weight_decay = 1e-4\n",
    "    overfitting_threshold = 3  # Number of consecutive epochs of overfitting to trigger adjustments\n",
    "    overfitting_epochs = 0\n",
    "\n",
    "    # Track historical loss differences for smarter overfitting detection\n",
    "    loss_differences = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}, Learning Rate: {lr:.6f}, Weight Decay: {weight_decay:.6f}\")\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        all_labels, all_preds = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        # Calculate metrics\n",
    "        val_f1, val_precision, val_recall = calculate_metrics(all_labels, all_preds)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Val F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation F1 Score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Best model saved!\")\n",
    "\n",
    "        # --- Smarter Overfitting Detection ---\n",
    "        loss_diff = val_loss - train_loss\n",
    "        acc_diff = train_acc - val_acc\n",
    "        loss_differences.append(loss_diff)\n",
    "\n",
    "        # Check rolling average of loss differences\n",
    "        if len(loss_differences) > 3:\n",
    "            rolling_avg_loss_diff = np.mean(loss_differences[-3:])\n",
    "            if rolling_avg_loss_diff > 0.1 and acc_diff > 0.1:\n",
    "                overfitting_epochs += 1\n",
    "                print(f\"Overfitting detected (Rolling Loss Diff: {rolling_avg_loss_diff:.4f}).\")\n",
    "            else:\n",
    "                overfitting_epochs = 0\n",
    "\n",
    "        if overfitting_epochs >= overfitting_threshold:\n",
    "            print(\"Overfitting persists. Adjusting learning rate and weight decay.\")\n",
    "            lr *= 0.5\n",
    "            weight_decay *= 0.9\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "                param_group['weight_decay'] = weight_decay\n",
    "            overfitting_epochs = 0  # Reset counter\n",
    "\n",
    "    # Explain model predictions with LIME after training\n",
    "    explain_with_lime(model, val_loader, device)\n",
    "\n",
    "# SMOTE: Handle imbalanced datasets\n",
    "def apply_smote(train_loader):\n",
    "    smote = SMOTE()\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        train_data.extend(inputs.view(inputs.size(0), -1).numpy())\n",
    "        train_labels.extend(labels.numpy())\n",
    "\n",
    "    train_data_smote, train_labels_smote = smote.fit_resample(np.array(train_data), np.array(train_labels))\n",
    "    print(\"SMOTE applied. Resampled dataset size:\", len(train_labels_smote))\n",
    "\n",
    "    return train_data_smote, train_labels_smote\n",
    "\n",
    "# LIME: Explain predictions\n",
    "def explain_with_lime(model, val_loader, device):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            sample_image = inputs[0].cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "            explanation = explainer.explain_instance(\n",
    "                image=sample_image,\n",
    "                classifier_fn=lambda x: model(torch.tensor(x.transpose(0, 3, 1, 2)).float().to(device)).detach().cpu().numpy(),\n",
    "                top_labels=2,\n",
    "                hide_color=0,\n",
    "                num_samples=1000\n",
    "            )\n",
    "\n",
    "            temp, mask = explanation.get_image_and_mask(\n",
    "                label=1,  # Assuming class 1 is \"Not Healthy\"\n",
    "                positive_only=True,\n",
    "                num_features=10,\n",
    "                hide_rest=False\n",
    "            )\n",
    "\n",
    "            lime_image = mark_boundaries(temp, mask)\n",
    "            plt.imshow(lime_image)\n",
    "            plt.title(\"LIME Explanation\")\n",
    "            plt.show()\n",
    "            break  # Explain one sample for demonstration\n",
    "\n",
    "# Preprocess dataset with SMOTE\n",
    "train_data_smote, train_labels_smote = apply_smote(train_loader)\n",
    "\n",
    "# Train model with the new improvements\n",
    "train_model_with_smote_and_explainability(model, criterion, optimizer, train_loader, val_loader, device, epochs=15)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "#train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=15)\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(model.state_dict(), \"final_spectrogram_classifier_15.pth\")\n",
    "print(\"Model saved as final_spectrogram_classifier_15.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5719103-477f-4fad-94ed-5509bcb76a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
